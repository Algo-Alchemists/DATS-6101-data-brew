---
title: "Data Brew: Brewing Success with Starbucks Customer Data"
subtitle: "TEAM 6 - Chekitha Swayampu, Hrushikesh Sai Seshagiri Chowdary Uppalapati, Swathi Murali Srinivasan, Vaishnavi Tamilvanan"
date: "2023-12-13"
output:
  rmdformats::readthedown:
    df_print: "kable"
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 
```

# DATASET OVERVIEW
```{r, results='markup'}
# Load data
```

```{r}
portfolio <- read.csv("data/portfolio.csv", row.names = 1)
profile <- read.csv("data/profile.csv", row.names = 1)
transcript <- read.csv("data/transcript.csv", row.names = 1)
```

## BEFORE CLEANING
### PORTFOLIO
```{r, results='markup'}
head(portfolio)
```
### PROFILE
```{r, results='markup'}
head(profile)
```
### TRANSCRIPT
```{r, results='markup'}
head(transcript)
```
## DATA CLEANING
```{r, results='markup'}
# Expand "channels" into binary columns of all different channels in the dataset (email, web, mobile, social)

library(dplyr)
```

```{r}
library(stringr)

# Create binary columns for each channel
channels_list <- c('email', 'web', 'mobile', 'social')

portfolio_channels <- portfolio %>%
  mutate(email = as.numeric(str_detect(channels, 'email')),
         web = as.numeric(str_detect(channels, 'web')),
         mobile = as.numeric(str_detect(channels, 'mobile')),
         social = as.numeric(str_detect(channels, 'social')))


# Create binary columns for each offer type
portfolio_offertype <- portfolio %>%
  mutate(bogo = as.numeric(offer_type == 'bogo'),
         informational = as.numeric(offer_type == 'informational'),
         discount = as.numeric(offer_type == 'discount'))

merged_portfolio <- merge(portfolio, portfolio_channels, by = "id", all.x = TRUE) %>%
  merge(portfolio_offertype, by = "id", all.x = TRUE)

new_portfolio <- merged_portfolio %>%
  select(reward, difficulty, duration, offer_type, id, bogo, discount, informational, email, mobile, social, web)

unique_ids <- unique(new_portfolio$id)
id_mapping <- setNames(seq_along(unique_ids), unique_ids)

new_portfolio$id <- id_mapping[new_portfolio$id]

# Checking for null values in each column
```

```{r}
col_sums_null <- colSums(is.na(new_portfolio))

duplicated_rows <- new_portfolio[duplicated(new_portfolio), ]
```

### PROFILE

```{r, results='markup'}
unique_ids <- unique(profile$id)
id_mapping <- setNames(seq_along(unique_ids), unique_ids)

profile$id <- id_mapping[profile$id]
na_counts <- colSums(is.na(profile))
```

```{r}
cat("ORIGINAL NA VALUES:", na_counts)
```


```{r, results='markup'}
# Remove rows with NA values and Age equal to 118
profile_new <- subset(profile, !is.na(age) & age != 118)

na_counts_after_cleaning <- colSums(is.na(profile_new))
cat("Count of NA values afer removing:",na_counts_after_cleaning)

profile <- na.omit(profile_new)
```

```{r}
profile_new$became_member_on <- as.Date(as.character(profile_new$became_member_on), format = "%Y%m%d")

duplicated_rows <- profile_new[duplicated(profile_new), ]
```

### TRANSCRIPT

```{r}
library(dplyr)

# Extract offer_id from the 'value' column
transcript <- transcript %>%
  mutate(offer_id = ifelse(grepl("'offer id'", value),
                           gsub(".*'offer id':\\s*'([[:alnum:]]+)'.*", "\\1", value),
                           ifelse(grepl("'offer_id'", value),
                                  gsub(".*'offer_id':\\s*'([[:alnum:]]+)'.*", "\\1", value),
                                  NA)))
# Create amount column
transcript <- transcript %>%
  mutate(amount = ifelse(!is.na(str_extract(value, '"amount": ([0-9.]+)')), 
                         as.numeric(str_extract(value, '"amount": ([0-9.]+)')), 0))

# Create reward_given column
transcript <- transcript %>%
mutate(reward_given = ifelse(!is.na(str_extract(value, '"reward": ([0-9]+)')), 
                               as.numeric(str_extract(value, '"reward": ([0-9]+)')), 0))

# Remove value column
transcript <- select(transcript, -value)

if (!requireNamespace("digest", quietly = TRUE)) {
  install.packages("digest")
}
library(digest)


# Function to convert person value to an integer
map_person_to_int <- function(person_value) {
# Calculate the hash value using SHA-256
hash_value <- digest(person_value, algo = "sha256", serialize = FALSE)
# Convert the hash value to a numeric representation
  person_integer <- sum(as.integer(charToRaw(hash_value)))
  
  return(person_integer)
}
transcript$person <- sapply(transcript$person, map_person_to_int)

# Create a mapping dictionary
unique_ids <- unique(transcript$offer_id)
id_mapping <- setNames(seq_along(unique_ids), unique_ids)

transcript$offer_id <- id_mapping[transcript$offer_id]
```

```{r}
library(dplyr)

# Create binary columns for each event
event_list <- c('offer completed', 'offer received', 'offer viewed', 'transaction')

transcript_new <- transcript %>%
  mutate(offer_completed = as.numeric(event == 'offer completed'),
         offer_received = as.numeric(event == 'offer received'),
         offer_viewed = as.numeric(event == 'offer viewed'),
         transaction = as.numeric(event == 'transaction'))

# Display the updated data frame
head(transcript_new)
```

### PORTFOLIO

```{r, results='markup'}

library(dplyr)

# Rename columns in the 'portfolio' data frame
new_portfolio <- new_portfolio %>%
  rename(offer_id = id, offer_reward = reward)

transcript1 <- read.csv("data/transcript.csv", row.names =1)
profile1 <- read.csv("data/profile.csv", row.names = 1)
profile1$gender <- as.factor(profile1$gender)

# Impute missing values in 'income' with mean
profile1$income[is.na(profile1$income)] <- mean(profile1$income, na.rm = TRUE)

# Remove any non-numerc characters
profile1$became_member_on <- gsub("[^0-9]", "", profile1$became_member_on)

profile1$became_member_on <- as.Date(profile1$became_member_on, format = "%Y%m%d")
profile1$membership_duration <- as.numeric(difftime(Sys.Date(), profile1$became_member_on, units = "days"))
profile1$membership_duration <- as.numeric(difftime(Sys.Date(), profile1$became_member_on, units = "days"))

library(jsonlite)

# Extract offer id from 'value' column
transcript1$value <- gsub("'", "\"", transcript1$value)  # Replace single quotes with double quotes
transcript1$offer_id <- sapply(transcript1$value, function(x) {
  parsed_value <- fromJSON(x, simplifyVector = TRUE)
  if (!is.null(parsed_value) && 'offer id' %in% names(parsed_value)) {
    return(parsed_value[['offer id']])
  } else {
    return(NA)
  }
})

# Create binary columns for different events
transcript1$offer_received <- as.integer(transcript1$event == "offer received")
transcript1$offer_viewed <- as.integer(transcript1$event == "offer viewed")
transcript1$offer_completed <- as.integer(transcript1$event == "offer completed")
transcript1$transaction <- as.integer(transcript1$event == "transaction")

# Rename columns in the 'transcript' data frame
transcript_new <- transcript_new %>%
  rename(user_id = person)

# Rename columns in the 'profile' data frame
profile_new <- profile_new %>%
  rename(user_id = id)

# Left join on 'offer_id'
full_df <- left_join(transcript_new, new_portfolio, by = 'offer_id')

# Inner join on 'user_id'
full_df <- inner_join(full_df, profile_new, by = 'user_id')

head(new_portfolio)

```

### MERGED DATA

```{r, results='markup'}
# Merge profile and transcript datasets based on 'id' (customer ID)
merged_data <- merge(profile1, transcript1, by.x = "id", by.y = "person", all.x = TRUE)

merged_data <- merge(merged_data, portfolio, by.x = "offer_id", by.y = "id", all.x = TRUE)

head(merged_data)
```

# EXPLORATORY DATA ANALYSIS


## Age and Gender

```{r, results='markup'}
# Create a side-by-side boxplot and histogram
par(mfrow = c(1, 2), mar = c(5, 4, 4, 2))
boxplot(profile_new$age, xlab = "Age", main = "Boxplot", col = "lightblue")
hist(profile_new$age, xlab = "Age", main = "Histogram", col = "lightblue")

# Adjust axis label sizes
par(cex.lab = 1.5)

# Print descriptive statistics
summary(profile_new$age)
age_sd <- sd(profile_new$age)

# Print the standard deviation
cat("Standard Deviation of Age:", age_sd, "\n")
```





## Gender distribution.
```{r, results='markup'}
library(ggplot2)
library(plotly)

# Create a data frame with the count of each gender category
gender_counts <- table(profile$gender)

# Calculate percentages
gender_percentages <- round((gender_counts / sum(gender_counts)) * 100, 1)

# Define custom colors
custom_colors <- c("#FF6F61", "#6B5B95", "#88B04B")  # You can use any color codes you like

# Create the 3D pie chart
pie_chart <- plot_ly(
  labels = names(gender_counts),
  values = gender_counts,
  type = "pie",
  textinfo = "label+percent",
  marker = list(colors = custom_colors),
  pull = c(0.1, 0.1, 0.2)  # Adjust pull for exploding wedges
) %>%
  layout(
    title = "Gender Distribution",
    scene = list(
      aspectmode = "cube",  # Center the chart
      camera = list(eye = list(x = 1.25, y = 1.25, z = 0.85))  # 3D view settings
    ),
    showlegend = FALSE
  )

# Display the 3D pie chart
pie_chart
```






## Data distribution among different events.

```{r, results='markup'}
library(ezids)
# Get value counts for the 'event' column
event_value_counts <- table(transcript_new$event)
# EDA on event occurences
# Load the required libraries
library(ggplot2)
library(plotly)

# Create a data frame from the event counts
event_counts_df <- data.frame(event = names(event_value_counts), count = as.numeric(event_value_counts))

# Define a vector of colors for  four events
event_colors <- c("Coral", "Cyan", "Magenta", "Turquoise")

# Create a ggplot2 bar chart 
p <- ggplot(event_counts_df, aes(x = event, y = count, fill = event)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = event_colors) +
  labs(title = "Event Distribution", x = "Event", y = "Count") +
  theme_minimal() +
  scale_y_continuous(breaks = seq(0, max(event_counts_df$count), by = 20000)) +
  coord_flip() +
  theme(panel.border = element_rect(color = "black", fill = NA),
        panel.grid = element_blank(),
        axis.text.x = element_text(face = "bold", color = "black"),
        axis.text.y = element_text(face = "bold", color = "black")) 

# Make the ggplot2 chart interactive using plotly
interactive_plot <- ggplotly(p)

# Display the interactive plot
interactive_plot
```




## Percentages of each offer type sent.

```{r, results='markup'}
colors <- c("#ad6a6c", "#d0ada7", "#e8d6cb")

# Count the frequency of each offer type
offer_counts <- table(new_portfolio$offer_type)

ggplot(data = as.data.frame(offer_counts), aes(x = Var1, y = Freq)) +
  geom_bar(stat = "identity", fill = colors, color = "black") +
  labs(title = "Frequency of Each Offer Type",
       x = "Offer Type",
       y = "Count") +
  scale_fill_manual(values = colors)
```





```{r, results='markup'}
# Load the ggplot2 library
library(ggplot2)

# Create a scatterplot
ggplot(profile_new, aes(x = gender, y = income, color = gender)) +
  geom_jitter(width = 0.3, alpha = 0.7, size = 1) +
  labs(title = "Scatterplot of Income vs Gender", x = "Gender", y = "Income") +
  scale_color_manual(values = c("#E41A1C", "#377EB8", "#4DAF4A")) +  # Custom colors
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        panel.grid.major.y = element_line(color = "gray90"),
        axis.text.x = element_text(angle = 45, hjust = 1))

```









## Income vs Gender vs Age
```{r, results='markup'}
# Load necessary libraries
library(plotly)
library(dplyr)

# Create a 3D scatterplot with Plotly
scatter_3d <- profile_new %>%
  plot_ly(x = ~age, y = ~income, z = ~gender, color = ~gender, colors = c("#E41A1C", "#377EB8", "#4DAF4A"),
          type = "scatter3d", mode = "markers",
          marker = list(size = 2)) %>%
  layout(scene = list(xaxis = list(title = "Age"),
                     yaxis = list(title = "Income"),
                     zaxis = list(title = "Gender")))

# Show the 3D scatterplot
scatter_3d
```











# DATA MODELLING

## SMART Q1: How can we design a precise predictive model to classify customer responses to offers as successful or not?
Now that we have analyzed the dataset, we will proceed by creating a model that would predict whether a user will respond to an offer or not. There are 4 scenarios that can happen:

A user will view and complete the offer.
A user will just view the offer.
A user will not view the offer, but will complete it anyway (without prior knowledge of the offer existence)
A user will not view the offer and will not complete it.

Since starbucks are targetting users that will view the offer and complete it afterwards, our prediction would be a binary value as such: 1: User will view and complete the offer 0: Otherwise


In order to proceed with the prediction, we will need to create a new dataframe that will include the targeted features and the prediction column. The features that will be analyzed are:

Age
Income
Gender
Offer_type
Reward
Duration
Difficulty
Channels














```{r, results='markup'}
library(dplyr)

# Filter offer_received_df
offer_received_df <- transcript_new %>%
  filter(offer_received == 1) %>%
  select(offer_id, user_id, time) %>%
  rename(time_received = time)

# Filter offer_viewed_df
offer_viewed_df <- transcript_new %>%
  filter(offer_viewed == 1) %>%
  select(offer_id, user_id, time) 
  


# Filter offer_completed_df
offer_completed_df <- transcript_new %>%
  filter(offer_completed == 1) %>%
  select(offer_id, user_id, time) 

# Merge offer_completed_df and offer_viewed_df
complete_bogo_discount_df <- merge(offer_completed_df, offer_viewed_df, by = c('offer_id', 'user_id'))

# Merge with offer_received_df
complete_bogo_discount_df <- merge(complete_bogo_discount_df, offer_received_df, by = c('offer_id', 'user_id'))

complete_bogo_discount_df <- complete_bogo_discount_df %>%
  rename(time_completed = time.x, time_viewed = time.y)


complete_bogo_discount_df <- merge(complete_bogo_discount_df, new_portfolio, by = 'offer_id')

# Display the resulting data frame
head(complete_bogo_discount_df)
```


```{r, results='markup'}
library(dplyr)


complete_bogo_discount_df <- complete_bogo_discount_df %>%
  mutate(time_expire = time_received + duration * 24)

# Display the resulting data frame
head(complete_bogo_discount_df)

```
```{r, results='markup'}
library(dplyr)

complete_bogo_discount_df <- complete_bogo_discount_df %>%
  filter(
    time_received <= time_viewed,
    time_viewed <= time_completed,
    time_completed <= time_expire
  )

# Display the resulting data frame
head(complete_bogo_discount_df)

```
We have created the first dataset, we will repeat similar logic to create second dataset.
```{r, results='markup'}
library(dplyr)

# Dataframe holding the events where a transaction took place
transaction_df <- transcript_new %>%
  filter(transaction == 1) %>%
  select(user_id, time, amount)

# Merge transaction and offer_viewed dataframes
complete_info_df <- left_join(transaction_df, offer_viewed_df, by = 'user_id')

# Merge with offer_received_df
complete_info_df <- left_join(complete_info_df, offer_received_df, by = c('offer_id', 'user_id'))
complete_info_df <- complete_info_df %>%
  rename(time_transaction = time.x, time_viewed = time.y)


# Merge with new_portfolio
complete_info_df <- left_join(complete_info_df, new_portfolio, by = 'offer_id')

# Calculate offer expiration
complete_info_df <- complete_info_df %>%
  mutate(time_expire = time_received + duration * 24)

# Choose only informational offer
complete_info_df <- filter(complete_info_df, informational == 1)

#filter based on the mentioned criteria
complete_info_df <- complete_info_df %>%
  filter(
    time_viewed >= time_received,
    time_transaction <= time_expire,
    time_viewed <= time_transaction
  )


complete_bogo_discount_df <- mutate(complete_bogo_discount_df, offer_success = 1)
complete_info_df <- mutate(complete_info_df, offer_success = 1)


complete_bogo_discount_df <- complete_bogo_discount_df %>%
  select(user_id, offer_id, offer_success)

complete_info_df <- complete_info_df %>%
  select(user_id, offer_id, offer_success)


head(complete_info_df)
```

```{r, results='markup'}
library(dplyr)
concat_r <- bind_rows(complete_bogo_discount_df, complete_info_df)

head(concat_r)
```

```{r, results='markup'}
library(dplyr)


df1 <- offer_received_df %>%
  select(offer_id, user_id) %>%
  distinct()  # Ensure unique pairs

df2 <- concat_r %>%
  select(offer_id, user_id, offer_success)

all_clean_df <- left_join(df1, df2, by = c('offer_id', 'user_id'))

# Consider the other offers as unsuccessful
all_clean_df$offer_success <- ifelse(is.na(all_clean_df$offer_success), 0, all_clean_df$offer_success)


all_clean_df <- data.frame(all_clean_df, row.names = NULL)


# Subset Columns
model_df <- all_clean_df %>%
  select(user_id, offer_id, offer_success)

# Merge with 'portfolio' DataFrame
model_df <- left_join(model_df, new_portfolio, by = 'offer_id')
# Merge with 'profile' DataFrame
model_df <- left_join(model_df, profile_new, by = 'user_id')

# Drop Columns
model_df <- model_df %>%
  select(-became_member_on, -offer_type)

head(model_df)
```


```{r, results='markup'}
normalize_data <- function(df, column) {
  # Min-Max Normalization
  df[[column]] <- (df[[column]] - min(df[[column]])) / (max(df[[column]]) - min(df[[column]]))
  
  # Return the modified data frame
  return(df)
}


# Create Integer Mapping for 'gender' Column
gender_levels <- unique(model_df$gender)
gender_map <- setNames(as.integer(seq_along(gender_levels)), gender_levels)

model_df$gender <- gender_map[model_df$gender]

# Normalize 'age' and 'income' Columns
normalize_data <- function(x) {
  return((x - min(x)) / (max(x) - min(x)))
}

model_df$age <- normalize_data(model_df$age)
model_df$income <- normalize_data(model_df$income)
```

Drop specified columns

```{r, results='markup'}
columns_to_drop <- c('gender', 'age', 'income')
model_df <- model_df[, !(names(model_df) %in% columns_to_drop)]

head(model_df)

```
